# Copy this file to backend/.env and update with your Databricks credentials
DATABRICKS_HOST=https://dbc-xxxx.cloud.databricks.com
DATABRICKS_TOKEN=your-token
DATABRICKS_WAREHOUSE_ID=your-warehouse-id

# Azure OpenAI (preferred)
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com
AZURE_OPENAI_API_KEY=your-azure-key
AZURE_OPENAI_DEPLOYMENT=gpt-4o-mini
# Optional overrides
# AZURE_OPENAI_API_VERSION=2024-02-15-preview
# LLM_TEMPERATURE=0.15

# Or provide OpenAI platform credentials instead
# OPENAI_API_KEY=sk-...
# OPENAI_MODEL=gpt-4o-mini

# Or run a local model through Ollama (free option)
# OLLAMA_BASE_URL=http://localhost:11434
# Optional fallback if the container cannot resolve host.docker.internal (common on some Linux setups)
# OLLAMA_FALLBACK_BASE_URL=http://172.17.0.1:11434
# OLLAMA_MODEL=llama3:8b-instruct
# OLLAMA_TIMEOUT=60

# Local development helpers (optional)
# LLM_MODE=mock

# Optional frontend origins (comma separated)
FRONTEND_ORIGINS=https://your-domain.com

# Cache tuning (seconds)
EARNINGS_CACHE_TTL=900
EARNINGS_CACHE_LIMIT=50000
VENDOR_CACHE_TTL=3600
VENDOR_CACHE_LIMIT=200000

# Scores feed
SCORES_TABLE=workspace.sw_gold.scores
SCORES_CACHE_TTL=600
SCORES_CACHE_LIMIT=200

# Company profiles
PROFILES_TABLE=workspace.sw_gold.nyse_profiles
PROFILES_CACHE_TTL=900
PROFILES_CACHE_LIMIT=5000
